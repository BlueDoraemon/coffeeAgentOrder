{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q -U google-generativeai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Long black\n",
      "#2 Machiatto\n",
      "#3 Iced Caramel Latte\n",
      "#4 Flat White\n",
      "#5 Latte\n",
      "#6 Cappucino\n",
      "#7 3/4 Double Ristretto Flat White\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "file_path = os.path.join(parent_dir, 'DB', 'testDatabase.txt')\n",
    "\n",
    "data = \"\"\n",
    "# Read the file\n",
    "with open(file_path, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt generation\n",
    "def generatePrompt(DATA: str, USER_ORDER: str) -> str:\n",
    "    return f\"\"\"\n",
    "    You are a coffee order assistant that maps customer orders to standard menu items.\n",
    "    Given a customer order, check the menu and provide the exact corresponding output.\n",
    "\n",
    "    Menu:\n",
    "    {DATA}\n",
    "\n",
    "    Input Order: {USER_ORDER}\n",
    "    Output Format: [menu_number] [size] [menu_item] [short additional notes: e.g. 3/4, how many sugars]\n",
    "\n",
    "    Rules:\n",
    "    - guess the coffee order output\n",
    "    - melbourne magic is a double ristretto flat white\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateJudgePrompt(output: str, DATA: str, USER_ORDER: str) -> str:\n",
    "    return f\"\"\"You are a precise coffee order validator that evaluates the accuracy of coffee order mappings. Your role is to judge whether the mapped order matches the customer's intent.\n",
    "\n",
    "Menu:\n",
    "{DATA}\n",
    "\n",
    "Original Customer Order: {USER_ORDER}\n",
    "Coffee agent guess: {output}\n",
    "\n",
    "Instructions:\n",
    "1. Analyze if the mapped order accurately represents the customer's intent\n",
    "2. Consider common coffee order variations and aliases\n",
    "3. Account for regional naming conventions (e.g., Melbourne Magic = Double Ristretto Flat White)\n",
    "4. Check for specific customizations (size, strength, milk type)\n",
    "\n",
    "Evaluation Criteria:\n",
    "- Base drink match (e.g., latte, cappuccino, flat white)\n",
    "- Drink size if specified\n",
    "- Coffee strength (single/double shot, ristretto)\n",
    "- Milk type if specified\n",
    "- Temperature preference if mentioned\n",
    "- Additional modifications (extra hot, no foam, etc.)\n",
    "\n",
    "\"\"\" + \"\"\"Output Format:\n",
    "{\n",
    "    \"is_valid\": boolean,\n",
    "    \"confidence\": float (0.0-1.0),\n",
    "    \"explanation\": string,\n",
    "    \"suggested_correction\": string (if is_valid is false)\n",
    "}\n",
    "\n",
    "Example Response:\n",
    "{\n",
    "    \"is_valid\": true,\n",
    "    \"confidence\": 0.95,\n",
    "    \"explanation\": \"Correctly mapped 'magic' to 'Double Ristretto Flat White'\",\n",
    "    \"suggested_correction\": null\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "MODEL = \"gemini-2.0-flash-exp\"\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable not found\")\n",
    "\n",
    "genai.configure(api_key = api_key)\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "judgeModel = genai.GenerativeModel(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Order: large mocha\n",
      "Output Format: [5] large Latte\n",
      "\n",
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"```json\\n{\\n    \\\"is_valid\\\": false,\\n    \\\"confidence\\\": 0.2,\\n    \\\"explanation\\\": \\\"The customer ordered a 'large mocha'. A mocha is a chocolate-flavored latte, and not simply a latte. The size is correctly captured as 'large'.\\\",\\n     \\\"suggested_correction\\\": \\\"[5] large Latte with chocolate\\\"\\n}\\n```\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ],\n",
      "          \"avg_logprobs\": -0.3289094785364663\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 677,\n",
      "        \"candidates_token_count\": 82,\n",
      "        \"total_token_count\": 759\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# get user order\n",
    "USER_ORDER = \"large mocha\"\n",
    "PROMPT = generatePrompt(data,USER_ORDER)\n",
    "response = model.generate_content(PROMPT)\n",
    "print(response.text)\n",
    "judgeResponse = judgeModel.generate_content(generateJudgePrompt(response,data,USER_ORDER))\n",
    "print(judgeResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# parse the output to only get the product\n",
    "import re\n",
    "\n",
    "def extract_number(text):\n",
    "    # Find first number in string\n",
    "    match = re.search(r'\\d+', text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "text = response.text\n",
    "output_id = extract_number(text)\n",
    "print(output_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
